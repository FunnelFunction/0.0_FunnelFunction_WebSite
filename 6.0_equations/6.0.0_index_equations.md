# Equations Index

> **6.0_equations** - Mathematical implementations in Python and PyTorch

---

## Purpose

This section contains the **actual code** for all Funnel Function equations:
- Pure Python implementations
- PyTorch differentiable models
- Unit tests and validation

These are the equations that power the simulators and validate the whitepapers.

---

## Contents

| Folder | Equation | Status | Description |
|--------|----------|--------|-------------|
| [6.1_equation_master_funnel_function/](./6.1_equation_master_funnel_function/) | f(x) | âœ… Python + PyTorch | The Master Equation |
| [6.2_equation_commitment_function/](./6.2_equation_commitment_function/) | f(Commitment) | âœ… Python + PyTorch | Trust decomposition |
| [6.3_equation_attention_function/](./6.3_equation_attention_function/) | ð’œ | ðŸ“‹ Planned | Dynamic attention |

---

## Implementation Files

### 6.1 Master Funnel Function

| File | Description |
|------|-------------|
| `6.1.2_implementation.py` | Pure Python implementation |
| `6.1.3_model_pytorch.py` | **NEW** Differentiable PyTorch model |

### 6.2 Commitment Function

| File | Description |
|------|-------------|
| `6.2.2_implementation.py` | **NEW** Pure Python implementation |
| `6.2.3_model_pytorch.py` | **NEW** Differentiable PyTorch model |

---

## Equation Summary

### Master Funnel Function f(x)

```python
# Python implementation
from equations.funnel_function import funnel_function

result = funnel_function(
    body=0.8,      # B: Somatic certainty [0, 1]
    mind=0.7,      # M: Prediction confidence [0, 1]
    soul=0.9,      # S: Identity congruence [0, 1]
    noise=0.2,     # N: Environmental interference
    load=0.3,      # L: Cognitive burden
    friction=0.1,  # Î˜: Barriers to action
    writability=1.0  # W: Receptivity gate [0, 1]
)
# f(x) = (B Â· M Â· S) / (N + L + Î˜) Ã— W
```

### Commitment Function f(Commitment)

```python
# Python implementation
from equations.commitment_function import commitment_function, CommitmentInputs

inputs = CommitmentInputs(
    p_transactional=0.85,      # Initial purchase probability
    archetype_resonance=0.95,  # Brand archetype match
    identity_utility=0.90,     # Identity enhancement
    service_latency=0.1,       # Support response time
    unforeseen_costs=0.05,     # Hidden fees
    support_friction=0.15      # Help accessibility
)
result = commitment_function(inputs)
# f(Commitment) = P_Transactional Ã— P_Enduring
```

---

## PyTorch Models

Each equation has a **differentiable PyTorch implementation** enabling:

### Capabilities

| Feature | Description |
|---------|-------------|
| **Gradient Optimization** | Find optimal inputs for target outputs |
| **Sensitivity Analysis** | Understand which variables matter most |
| **Batch Processing** | Process thousands of scenarios simultaneously |
| **Neural Integration** | Use as layers in larger models |
| **Inverse Solving** | Given desired outcome, find required inputs |

### Usage Examples

```python
import torch
from equations.model_pytorch import FunnelFunction, AttentionOptimizer

# Basic differentiable calculation
ff = FunnelFunction()
attention = ff(
    body=torch.tensor(0.8),
    mind=torch.tensor(0.7),
    soul=torch.tensor(0.9),
    noise=torch.tensor(0.2),
    load=torch.tensor(0.3),
    friction=torch.tensor(0.1)
)

# Batch processing (3 scenarios at once)
batch_attention = ff(
    body=torch.tensor([0.8, 0.5, 0.9]),
    mind=torch.tensor([0.7, 0.8, 0.6]),
    soul=torch.tensor([0.9, 0.6, 0.7]),
    noise=torch.tensor([0.2, 0.4, 0.1]),
    load=torch.tensor([0.3, 0.2, 0.2]),
    friction=torch.tensor([0.1, 0.3, 0.1])
)

# Optimization: find inputs for target attention
optimizer = AttentionOptimizer(ff)
optimal = optimizer.optimize_signal(target_attention=0.8)
print(f"Optimal B={optimal['body']:.2f}, M={optimal['mind']:.2f}, S={optimal['soul']:.2f}")

# Sensitivity analysis
sensitivity = optimizer.sensitivity_analysis()
print(f"Most sensitive to: {max(sensitivity, key=sensitivity.get)}")
```

### Learnable Models

```python
from equations.model_pytorch import LearnableFunnelFunction

# Model that learns optimal channel weights from data
model = LearnableFunnelFunction()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Training loop (fit to historical conversion data)
for epoch in range(100):
    predicted = model(body, mind, soul, noise, load, friction)
    loss = criterion(predicted, actual_conversions)
    loss.backward()
    optimizer.step()

# After training, see learned weights
print(model.get_weights())
# {'body': 1.2, 'mind': 0.8, 'soul': 1.5, ...}  # Domain-specific importance
```

---

## Requirements

```
torch>=2.0.0
numpy>=1.20.0
```

---

## Testing

```bash
# Run all equation tests
python -m pytest 6.0_equations/ -v

# Run specific equation tests
python -m pytest 6.1_equation_master_funnel_function/6.1.4_tests.py -v
```

---

*Last updated: 2025-12-11*
